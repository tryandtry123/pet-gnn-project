"""
æ··æ·†çŸ©é˜µåˆ†ææ¨¡å—
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from pathlib import Path

# å¯¼å…¥å­—ä½“å·¥å…·
import sys
sys.path.append('..')
try:
    from utils.plot_utils import setup_chinese_font, get_chinese_labels, save_figure_with_chinese_support
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„è®¾ç½®
    def setup_chinese_font():
        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            return True
        except:
            return False
    
    def get_chinese_labels():
        return {
            'title_confusion': 'PET Low-Coupling Event Recognition - Confusion Matrix',
            'xlabel_confusion': 'Predicted Label',
            'ylabel_confusion': 'True Label',
            'class_names': ['Valid Event', 'Low-Coupling Event']
        }
    
    def save_figure_with_chinese_support(fig, filepath, dpi=300, bbox_inches='tight'):
        fig.savefig(filepath, dpi=dpi, bbox_inches=bbox_inches, facecolor='white')

# è®¾ç½®ä¸­æ–‡å­—ä½“
setup_chinese_font()


def plot_confusion_matrix(y_true, y_pred, class_names=None, normalize=None, 
                         title=None, save_path=None, figsize=(8, 6)):
    """
    ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ ‡ç­¾
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        normalize: æ ‡å‡†åŒ–æ–¹å¼ ('true', 'pred', 'all', None)
        title: å›¾æ ‡é¢˜
        save_path: ä¿å­˜è·¯å¾„
        figsize: å›¾å½¢å¤§å°
    """
    # è·å–æ ‡ç­¾é…ç½®
    labels = get_chinese_labels()
    
    if class_names is None:
        class_names = labels['class_names']
    
    if title is None:
        title = labels['title_confusion']
    
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)
    
    # æ ‡å‡†åŒ–
    if normalize == 'true':
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        fmt = '.2%'
    elif normalize == 'pred':
        cm = cm.astype('float') / cm.sum(axis=0)
        fmt = '.2%'
    elif normalize == 'all':
        cm = cm.astype('float') / cm.sum()
        fmt = '.2%'
    else:
        fmt = 'd'
    
    # åˆ›å»ºå›¾å½¢
    plt.figure(figsize=figsize)
    
    # ä½¿ç”¨seabornç»˜åˆ¶çƒ­åŠ›å›¾
    ax = sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',
                     xticklabels=class_names, yticklabels=class_names,
                     cbar_kws={'label': 'Count' if normalize is None else 'Proportion'})
    
    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
    plt.title(title, fontsize=14, fontweight='bold', pad=20)
    plt.xlabel(labels['xlabel_confusion'], fontsize=12)
    plt.ylabel(labels['ylabel_confusion'], fontsize=12)
    
    # æ—‹è½¬æ ‡ç­¾ä»¥æ›´å¥½æ˜¾ç¤º
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    accuracy = np.trace(cm) / np.sum(cm) if normalize is None else np.trace(cm) / len(class_names)
    plt.figtext(0.02, 0.02, f'Accuracy: {accuracy:.3f}', fontsize=10,
               bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.7))
    
    plt.tight_layout()
    
    if save_path:
        save_figure_with_chinese_support(plt.gcf(), save_path)
    
    return cm


def analyze_confusion_matrix(y_true, y_pred, class_names=None):
    """
    åˆ†ææ··æ·†çŸ©é˜µï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯åˆ†æ
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ ‡ç­¾  
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        
    Returns:
        dict: åˆ†æç»“æœ
    """
    # è·å–æ ‡ç­¾é…ç½®
    labels = get_chinese_labels()
    
    if class_names is None:
        class_names = labels['class_names']
    
    cm = confusion_matrix(y_true, y_pred)
    n_classes = len(class_names)
    
    print("=" * 60)
    print("ğŸ” æ··æ·†çŸ©é˜µè¯¦ç»†åˆ†æ")
    print("=" * 60)
    
    # æ€»ä½“ç»Ÿè®¡
    total_samples = np.sum(cm)
    correct_predictions = np.trace(cm)
    accuracy = correct_predictions / total_samples
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"  æ­£ç¡®é¢„æµ‹: {correct_predictions}")
    print(f"  å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # å„ç±»åˆ«ç»Ÿè®¡
    print(f"\nğŸ“‹ å„ç±»åˆ«è¯¦ç»†åˆ†æ:")
    for i in range(n_classes):
        true_positives = cm[i, i]
        false_positives = np.sum(cm[:, i]) - true_positives
        false_negatives = np.sum(cm[i, :]) - true_positives
        true_negatives = total_samples - true_positives - false_positives - false_negatives
        
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\n  {class_names[i]}:")
        print(f"    çœŸæ­£ä¾‹ (TP): {true_positives}")
        print(f"    å‡æ­£ä¾‹ (FP): {false_positives}")
        print(f"    å‡è´Ÿä¾‹ (FN): {false_negatives}")
        print(f"    çœŸè´Ÿä¾‹ (TN): {true_negatives}")
        print(f"    ç²¾ç¡®ç‡: {precision:.4f}")
        print(f"    å¬å›ç‡: {recall:.4f}")
        print(f"    F1åˆ†æ•°: {f1_score:.4f}")
    
    # é”™è¯¯æ¨¡å¼åˆ†æ
    print(f"\nâš ï¸ é”™è¯¯æ¨¡å¼åˆ†æ:")
    for i in range(n_classes):
        for j in range(n_classes):
            if i != j and cm[i, j] > 0:
                error_rate = cm[i, j] / np.sum(cm[i, :]) * 100
                print(f"  {class_names[i]} â†’ {class_names[j]}: {cm[i, j]} ä¸ªæ ·æœ¬ ({error_rate:.2f}%)")
    
    # ç±»åˆ«å¹³è¡¡åˆ†æ
    print(f"\nâš–ï¸ ç±»åˆ«å¹³è¡¡åˆ†æ:")
    for i, class_name in enumerate(class_names):
        class_total = np.sum(cm[i, :])
        class_ratio = class_total / total_samples * 100
        print(f"  {class_name}: {class_total} ä¸ªæ ·æœ¬ ({class_ratio:.2f}%)")
    
    print("=" * 60)
    
    # è¿”å›åˆ†æç»“æœ
    analysis = {
        'confusion_matrix': cm,
        'accuracy': accuracy,
        'total_samples': total_samples,
        'correct_predictions': correct_predictions,
        'class_statistics': {}
    }
    
    for i in range(n_classes):
        tp = cm[i, i]
        fp = np.sum(cm[:, i]) - tp
        fn = np.sum(cm[i, :]) - tp
        tn = total_samples - tp - fp - fn
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        analysis['class_statistics'][class_names[i]] = {
            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn,
            'precision': precision, 'recall': recall, 'f1_score': f1
        }
    
    return analysis


def plot_normalized_confusion_matrices(y_true, y_pred, class_names=None, save_dir=None, figsize=(15, 5)):
    """
    ç»˜åˆ¶å¤šç§æ ‡å‡†åŒ–æ–¹å¼çš„æ··æ·†çŸ©é˜µå¯¹æ¯”
    """
    # è·å–æ ‡ç­¾é…ç½®
    labels = get_chinese_labels()
    
    if class_names is None:
        class_names = labels['class_names']
    
    fig, axes = plt.subplots(1, 3, figsize=figsize)
    fig.suptitle('Confusion Matrix Analysis', fontsize=16, fontweight='bold')
    
    normalizations = [None, 'true', 'pred']
    titles = ['Raw Counts', 'Normalized by True', 'Normalized by Prediction']
    
    for i, (norm, title) in enumerate(zip(normalizations, titles)):
        cm = confusion_matrix(y_true, y_pred)
        
        if norm == 'true':
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            fmt = '.2%'
        elif norm == 'pred':
            cm = cm.astype('float') / cm.sum(axis=0)
            fmt = '.2%'
        else:
            fmt = 'd'
        
        plt.subplot(1, 3, i+1)
        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title(title)
        plt.xlabel(labels['xlabel_confusion'])
        if i == 0:
            plt.ylabel(labels['ylabel_confusion'])
    
    plt.tight_layout()
    
    if save_dir:
        save_path = Path(save_dir) / 'confusion_matrix_comparison.png'
        save_figure_with_chinese_support(fig, save_path)
    
    return fig 