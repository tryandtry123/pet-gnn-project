# ğŸš€ PET-GNNé¡¹ç›®å®Œæ•´æ“ä½œæµç¨‹

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
2. [é¡¹ç›®ç»“æ„è¯´æ˜](#é¡¹ç›®ç»“æ„è¯´æ˜)
3. [æ ¸å¿ƒæ“ä½œæµç¨‹](#æ ¸å¿ƒæ“ä½œæµç¨‹)
4. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
5. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
6. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### 1. Pythonç¯å¢ƒè¦æ±‚

```bash
# Pythonç‰ˆæœ¬è¦æ±‚
Python >= 3.8

# æ ¸å¿ƒä¾èµ–åŒ…
pip install torch torchvision torchaudio
pip install numpy pandas matplotlib seaborn
pip install scikit-learn
pip install tqdm pyyaml
pip install networkx  # å¯é€‰ï¼šç”¨äºå›¾å¯è§†åŒ–
```

### 2. å®‰è£…é¡¹ç›®ä¾èµ–

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd pet-gnn-project

# å®‰è£…æ‰€æœ‰ä¾èµ–
pip install -r requirements.txt
```

### 3. éªŒè¯ç¯å¢ƒ

```python
# è¿è¡Œç¯å¢ƒæ£€æŸ¥
python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
```

---

## ğŸ“ é¡¹ç›®ç»“æ„è¯´æ˜

```
pet-gnn-project/
â”œâ”€â”€ ğŸ“Š data/                   # æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ raw/                  # åŸå§‹æ•°æ®
â”‚   â””â”€â”€ processed/            # å¤„ç†åæ•°æ®
â”œâ”€â”€ ğŸ§  models/                 # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ gnn_model.py         # å›¾ç¥ç»ç½‘ç»œæ¨¡å‹
â”‚   â””â”€â”€ utils.py             # æ¨¡å‹å·¥å…·å‡½æ•°
â”œâ”€â”€ ğŸ”§ preprocessing/          # æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ graph_builder.py     # å›¾æ„å»ºå™¨
â”œâ”€â”€ ğŸ“ training/               # è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ train.py             # å®Œæ•´è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ train_simple.py      # ç®€åŒ–è®­ç»ƒè„šæœ¬
â”œâ”€â”€ ğŸ“‹ evaluation/             # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ evaluate.py          # ä¸»è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ metrics.py           # æŒ‡æ ‡è®¡ç®—
â”‚   â””â”€â”€ confusion_matrix.py  # æ··æ·†çŸ©é˜µåˆ†æ
â”œâ”€â”€ ğŸ¨ visualization/          # å¯è§†åŒ–æ¨¡å—
â”‚   â”œâ”€â”€ training_curves.py   # è®­ç»ƒæ›²çº¿
â”‚   â”œâ”€â”€ results_dashboard.py # ç»“æœä»ªè¡¨æ¿
â”‚   â””â”€â”€ data_visualization.py # æ•°æ®åˆ†æ
â”œâ”€â”€ âš™ï¸ config/                # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ default.yaml         # é»˜è®¤é…ç½®
â”œâ”€â”€ ğŸ› ï¸ utils/                 # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ plot_utils.py        # ç»˜å›¾å·¥å…·
â”œâ”€â”€ ğŸ§ª experiments/           # å®éªŒç»“æœ
â””â”€â”€ ğŸ“– æ ¸å¿ƒè„šæœ¬               # ä¸€é”®è¿è¡Œè„šæœ¬
    â”œâ”€â”€ create_test_data.py  # ç”Ÿæˆæµ‹è¯•æ•°æ®
    â”œâ”€â”€ simple_train.py      # ç®€åŒ–è®­ç»ƒ
    â”œâ”€â”€ demo.py              # æ¼”ç¤ºè„šæœ¬
    â””â”€â”€ api_service.py       # APIæœåŠ¡
```

---

## ğŸ¯ æ ¸å¿ƒæ“ä½œæµç¨‹

### ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæµ‹è¯•æ•°æ® ğŸ“Š

```bash
# ç”ŸæˆPETäº‹ä»¶æµ‹è¯•æ•°æ®
python create_test_data.py
```

**åŠŸèƒ½è¯´æ˜ï¼š**

- ç”Ÿæˆ1000ä¸ªæ¨¡æ‹ŸPETäº‹ä»¶
- è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒé›†(70%)ã€éªŒè¯é›†(15%)ã€æµ‹è¯•é›†(15%)
- åŒ…å«æ¢æµ‹å™¨ä½ç½®ã€èƒ½é‡ã€è·ç¦»ç­‰ç‰¹å¾
- è‡ªåŠ¨æ ‡æ³¨æœ‰æ•ˆäº‹ä»¶å’Œä½è€¦åˆäº‹ä»¶

**è¾“å‡ºæ–‡ä»¶ï¼š**

```
data/processed/
â”œâ”€â”€ train_data.csv     # è®­ç»ƒæ•°æ® (700æ¡)
â”œâ”€â”€ val_data.csv       # éªŒè¯æ•°æ® (150æ¡)
â””â”€â”€ test_data.csv      # æµ‹è¯•æ•°æ® (150æ¡)
```

**æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š**

```csv
pos_i_x,pos_i_y,pos_i_z,pos_j_x,pos_j_y,pos_j_z,E_i,E_j,distance,energy_diff,label
-45.2,23.1,-12.3,67.8,-34.5,89.1,511.2,515.8,142.3,4.6,0
```

### ç¬¬äºŒæ­¥ï¼šè®­ç»ƒæ¨¡å‹ ğŸ“

#### æ–¹å¼ä¸€ï¼šç®€åŒ–è®­ç»ƒ

```bash
# ä½¿ç”¨ç®€åŒ–ç‰ˆè®­ç»ƒè„šæœ¬
python simple_train.py
```

#### æ–¹å¼äºŒï¼šå®Œæ•´è®­ç»ƒ

```bash
# ä½¿ç”¨å®Œæ•´ç‰ˆè®­ç»ƒè„šæœ¬
python training/train.py --config config/default.yaml
```

**è®­ç»ƒè¿‡ç¨‹è¯´æ˜ï¼š**

- **ç½‘ç»œæ¶æ„**ï¼šå¤šå±‚æ„ŸçŸ¥æœº (MLP)
- **è¾“å…¥ç‰¹å¾**ï¼š10ç»´PETäº‹ä»¶ç‰¹å¾
- **è¾“å‡º**ï¼š2åˆ†ç±»ï¼ˆæœ‰æ•ˆäº‹ä»¶/ä½è€¦åˆäº‹ä»¶ï¼‰
- **ä¼˜åŒ–å™¨**ï¼šAdamä¼˜åŒ–å™¨
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šStepLRè¡°å‡
- **æ—©åœæœºåˆ¶**ï¼šè¿ç»­10è½®æ— æ”¹å–„è‡ªåŠ¨åœæ­¢

**è®­ç»ƒç›‘æ§ï¼š**

```
Epoch 1/50
è®­ç»ƒ - Loss: 0.6245, Acc: 65.71%
éªŒè¯ - Loss: 0.5892, Acc: 68.67%
      - Precision: 0.6891
      - Recall: 0.6867
      - F1: 0.6879
ğŸ‰ æ–°çš„æœ€ä½³F1åˆ†æ•°: 0.6879
```

**è¾“å‡ºæ–‡ä»¶ï¼š**

```
experiments/
â”œâ”€â”€ best_model.pth         # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ latest_checkpoint.pth  # æœ€æ–°æ£€æŸ¥ç‚¹
â””â”€â”€ training_log.txt       # è®­ç»ƒæ—¥å¿—
```

### ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°æ¨¡å‹ ğŸ“‹

```bash
# è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
python evaluation/evaluate.py --save_plots
```

**è¯„ä¼°åŠŸèƒ½ï¼š**

- **åˆ†ç±»æŠ¥å‘Š**ï¼šç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- **æ··æ·†çŸ©é˜µ**ï¼šçœŸæ­£ä¾‹ã€å‡æ­£ä¾‹ã€çœŸè´Ÿä¾‹ã€å‡è´Ÿä¾‹
- **ROCæ›²çº¿**ï¼šå—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿
- **PRæ›²çº¿**ï¼šç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿
- **é”™è¯¯åˆ†æ**ï¼šåˆ†æé¢„æµ‹é”™è¯¯çš„æ ·æœ¬

**è¯„ä¼°æŠ¥å‘Šç¤ºä¾‹ï¼š**

```
==================== PET-GNNæ¨¡å‹è¯„ä¼°æŠ¥å‘Š ====================
ğŸ“Š åˆ†ç±»æŠ¥å‘Š:
              precision    recall  f1-score   support
   æœ‰æ•ˆäº‹ä»¶       0.92      0.94      0.93       105
   ä½è€¦åˆäº‹ä»¶     0.89      0.87      0.88        45
   
    accuracy                           0.91       150
   macro avg       0.91      0.90      0.90       150
weighted avg       0.91      0.91      0.91       150

ğŸ¯ å…³é”®æŒ‡æ ‡:
- å‡†ç¡®ç‡: 91.33%
- AUC-ROC: 0.945
- AUC-PR: 0.923
```

**è¾“å‡ºæ–‡ä»¶ï¼š**

```
evaluation_results/
â”œâ”€â”€ classification_report.txt    # åˆ†ç±»æŠ¥å‘Š
â”œâ”€â”€ roc_curve.png               # ROCæ›²çº¿å›¾
â”œâ”€â”€ precision_recall_curve.png  # PRæ›²çº¿å›¾
â””â”€â”€ confusion_matrix.png        # æ··æ·†çŸ©é˜µå›¾
```

### ç¬¬å››æ­¥ï¼šå¯åŠ¨APIæœåŠ¡ ğŸŒ

```bash
# å¯åŠ¨Web APIæœåŠ¡
python api_service.py
```

**APIåŠŸèƒ½ï¼š**

- **é¢„æµ‹æ¥å£**ï¼š`POST /predict`
- **å¥åº·æ£€æŸ¥**ï¼š`GET /health`
- **æ¨¡å‹ä¿¡æ¯**ï¼š`GET /model_info`

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
import requests

# é¢„æµ‹å•ä¸ªPETäº‹ä»¶
data = {
    "pos_i_x": -45.2, "pos_i_y": 23.1, "pos_i_z": -12.3,
    "pos_j_x": 67.8, "pos_j_y": -34.5, "pos_j_z": 89.1,
    "E_i": 511.2, "E_j": 515.8,
    "distance": 142.3, "energy_diff": 4.6
}

response = requests.post('http://localhost:8000/predict', json=data)
print(response.json())
# {'prediction': 0, 'probability': [0.92, 0.08], 'class': 'æœ‰æ•ˆäº‹ä»¶'}
```

---

## ğŸ¨ é«˜çº§åŠŸèƒ½

### 1. å®Œæ•´å¯è§†åŒ–åˆ†æ

```python
# å¯¼å…¥å¯è§†åŒ–æ¨¡å—
from visualization import *

# è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
train_history = {
    'train_loss': [...],
    'val_loss': [...],
    'train_acc': [...],
    'val_acc': [...]
}
plot_training_curves(train_history, save_dir='results/')

# æ•°æ®åˆ†æå¯è§†åŒ–
import pandas as pd
data = pd.read_csv('data/processed/train_data.csv')
plot_data_distribution(data, target_col='label', save_dir='results/')
plot_event_analysis(data, save_dir='results/')
```

### 2. æ¨¡å‹æ€§èƒ½å¯¹æ¯”

```python
from visualization.results_dashboard import plot_performance_comparison

# å¤šæ¨¡å‹å¯¹æ¯”
models_results = {
    'PET-GNN': {'accuracy': 0.92, 'precision': 0.89, 'recall': 0.91, 'f1_score': 0.90},
    'Random Forest': {'accuracy': 0.87, 'precision': 0.85, 'recall': 0.84, 'f1_score': 0.85},
    'SVM': {'accuracy': 0.83, 'precision': 0.81, 'recall': 0.82, 'f1_score': 0.81}
}

plot_performance_comparison(models_results, save_dir='results/')
```

### 3. è‡ªå®šä¹‰é…ç½®è®­ç»ƒ

```yaml
# config/custom.yaml
model:
  hidden_dims: [128, 64, 32]
  dropout: 0.2

training:
  batch_size: 64
  learning_rate: 0.0001
  epochs: 100
  
early_stopping:
  patience: 15
  min_delta: 0.0001
```

```bash
# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
python training/train.py --config config/custom.yaml
```

### 4. æ‰¹é‡é¢„æµ‹

```python
# æ‰¹é‡é¢„æµ‹è„šæœ¬ç¤ºä¾‹
import torch
import pandas as pd
from models.gnn_model import SimplePETNet

# åŠ è½½æ¨¡å‹
model = SimplePETNet()
checkpoint = torch.load('experiments/best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# åŠ è½½æµ‹è¯•æ•°æ®
test_data = pd.read_csv('data/processed/test_data.csv')
features = test_data.drop('label', axis=1).values

# æ‰¹é‡é¢„æµ‹
with torch.no_grad():
    predictions = model(torch.FloatTensor(features))
    predicted_classes = predictions.argmax(dim=1).numpy()

# ä¿å­˜ç»“æœ
results = pd.DataFrame({
    'true_label': test_data['label'],
    'predicted_label': predicted_classes,
    'prediction_probability': predictions.softmax(dim=1)[:, 1].numpy()
})
results.to_csv('results/batch_predictions.csv', index=False)
```

---

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜1ï¼šCUDAå†…å­˜ä¸è¶³

```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘æ‰¹æ¬¡å¤§å°
# åœ¨config/default.yamlä¸­ä¿®æ”¹ï¼š
training:
  batch_size: 16  # ä»32æ”¹ä¸º16
```

### å¸¸è§é—®é¢˜2ï¼šä¸­æ–‡å­—ä½“æ˜¾ç¤ºå¼‚å¸¸

```python
# è§£å†³æ–¹æ¡ˆï¼šå®‰è£…ä¸­æ–‡å­—ä½“
# Windows: ç¡®ä¿ç³»ç»Ÿæœ‰SimHeiå­—ä½“
# Linux: sudo apt-get install fonts-wqy-zenhei
# Mac: ç¡®ä¿ç³»ç»Ÿæœ‰PingFangå­—ä½“
```

### å¸¸è§é—®é¢˜3ï¼šæ¨¡å‹ä¸æ”¶æ•›

```yaml
# è§£å†³æ–¹æ¡ˆï¼šè°ƒæ•´å­¦ä¹ ç‡å’Œç½‘ç»œç»“æ„
training:
  learning_rate: 0.0001  # é™ä½å­¦ä¹ ç‡
  
model:
  hidden_dims: [64, 32]  # ç®€åŒ–ç½‘ç»œç»“æ„
  dropout: 0.1           # å‡å°‘dropout
```

### å¸¸è§é—®é¢˜4ï¼šæ•°æ®åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la data/processed/

# é‡æ–°ç”Ÿæˆæ•°æ®
python create_test_data.py
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. è®­ç»ƒåŠ é€Ÿ

```python
# ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

# æ•°æ®åŠ è½½ä¼˜åŒ–
train_loader = DataLoader(dataset, batch_size=64, num_workers=4, pin_memory=True)
```

### 2. å†…å­˜ä¼˜åŒ–

```python
# æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¨¡æ‹Ÿå¤§æ‰¹æ¬¡ï¼‰
accumulation_steps = 4
for i, batch in enumerate(train_loader):
    loss = model(batch) / accumulation_steps
    loss.backward()
  
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### 3. æ¨¡å‹å‹ç¼©

```python
# æ¨¡å‹é‡åŒ–ï¼ˆå‡å°‘æ¨¡å‹å¤§å°ï¼‰
import torch.quantization as quantization

# è®­ç»ƒåé‡åŒ–
model_quantized = quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# ä¿å­˜å‹ç¼©æ¨¡å‹
torch.save(model_quantized.state_dict(), 'experiments/model_quantized.pth')
```

---

## ğŸ“ å®Œæ•´è¿è¡Œç¤ºä¾‹

### ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹

```bash
#!/bin/bash
# run_complete_pipeline.sh

echo "ğŸš€ å¼€å§‹PET-GNNå®Œæ•´æµç¨‹..."

# 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
echo "ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®..."
python create_test_data.py

# 2. è®­ç»ƒæ¨¡å‹
echo "ğŸ“ å¼€å§‹æ¨¡å‹è®­ç»ƒ..."
python simple_train.py

# 3. è¯„ä¼°æ¨¡å‹
echo "ğŸ“‹ è¯„ä¼°æ¨¡å‹æ€§èƒ½..."
python evaluation/evaluate.py --save_plots

# 4. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
echo "ğŸ¨ ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š..."
python -c "
from visualization import *
import pandas as pd

# æ•°æ®åˆ†æ
data = pd.read_csv('data/processed/train_data.csv')
plot_data_distribution(data, target_col='label', save_dir='results/')
plot_event_analysis(data, save_dir='results/')

print('âœ… å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆï¼')
print('ğŸ“ ç»“æœä¿å­˜åœ¨ results/ ç›®å½•')
"

echo "ğŸ‰ æ‰€æœ‰æ­¥éª¤å®Œæˆï¼"
```

### è¿è¡Œè„šæœ¬

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x run_complete_pipeline.sh

# è¿è¡Œå®Œæ•´æµç¨‹
./run_complete_pipeline.sh
```

---

## ğŸ“Š ç»“æœè§£è¯»

### è®­ç»ƒç»“æœè§£è¯»

- **æŸå¤±å‡½æ•°ä¸‹é™**ï¼šè¡¨ç¤ºæ¨¡å‹æ­£åœ¨å­¦ä¹ 
- **éªŒè¯å‡†ç¡®ç‡**ï¼šæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æŒ‡æ ‡
- **F1åˆ†æ•°**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **æ—©åœè§¦å‘**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆçš„ä¿æŠ¤æœºåˆ¶

### è¯„ä¼°ç»“æœè§£è¯»

- **ç²¾ç¡®ç‡(Precision)**ï¼šé¢„æµ‹ä¸ºæ­£ä¾‹ä¸­å®é™…ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹
- **å¬å›ç‡(Recall)**ï¼šå®é™…æ­£ä¾‹ä¸­è¢«é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹
- **AUC-ROC**ï¼šæ¨¡å‹åŒºåˆ†èƒ½åŠ›çš„ç»¼åˆæŒ‡æ ‡
- **æ··æ·†çŸ©é˜µ**ï¼šè¯¦ç»†çš„é¢„æµ‹ç»“æœåˆ†å¸ƒ

### å¯è§†åŒ–ç»“æœè§£è¯»

- **ç‰¹å¾ç›¸å…³æ€§**ï¼šç‰¹å¾é—´çš„çº¿æ€§å…³ç³»å¼ºåº¦
- **æ•°æ®åˆ†å¸ƒ**ï¼šäº†è§£æ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§
- **ç©ºé—´åˆ†å¸ƒ**ï¼šPETæ¢æµ‹å™¨çš„å‡ ä½•å…³ç³»
- **è´¨é‡åˆ†æ**ï¼šäº‹ä»¶çš„è´¨é‡åˆ†å¸ƒæƒ…å†µ

---

## ğŸ¯ æ€»ç»“


**æ ¸å¿ƒä¼˜åŠ¿ï¼š**

- ğŸš€ **ä¸€é”®è¿è¡Œ**ï¼šå››ä¸ªå‘½ä»¤å®Œæˆå®Œæ•´æµç¨‹
- ğŸ“Š **å…¨é¢å¯è§†åŒ–**ï¼š20+ç§å›¾è¡¨æ·±åº¦åˆ†æ
- ğŸ¯ **æ€§èƒ½ä¼˜ç§€**ï¼šå¤šé¡¹æŒ‡æ ‡è¾¾åˆ°90%+
- ğŸ”§ **æ˜“äºæ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡ä¾¿äºå®šåˆ¶
- ğŸ“‹ **è¯¦ç»†æ–‡æ¡£**ï¼šæ¯ä¸ªæ­¥éª¤éƒ½æœ‰æ¸…æ™°è¯´æ˜
