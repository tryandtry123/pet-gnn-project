"""
PETä½è€¦åˆäº‹ä»¶è¯†åˆ« REST API æœåŠ¡
æä¾›æ¨¡å‹é¢„æµ‹ã€å¥åº·æ£€æŸ¥ç­‰æ¥å£
"""

# ä¾èµ–æ£€æŸ¥
import sys
import os
import traceback

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    missing_deps = []
    
    try:
        import flask
    except ImportError:
        missing_deps.append('flask')
    
    try:
        import torch
    except ImportError:
        missing_deps.append('torch')
    
    try:
        import numpy as np
    except ImportError:
        missing_deps.append('numpy')
    
    try:
        import pandas as pd
    except ImportError:
        missing_deps.append('pandas')
    
    try:
        import yaml
    except ImportError:
        missing_deps.append('pyyaml')
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘å¿…è¦ä¾èµ–: {', '.join(missing_deps)}")
        print("è¯·è¿è¡Œ: pip install " + " ".join(missing_deps))
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡")
    return True

# æ£€æŸ¥ä¾èµ–
if not check_dependencies():
    print("ğŸ›‘ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼ŒAPIæœåŠ¡æ— æ³•å¯åŠ¨")
    sys.exit(1)

# å¯¼å…¥å…¶ä»–æ¨¡å—
from flask import Flask, request, jsonify, render_template_string
import torch
import numpy as np
import pandas as pd
import json
import logging
from pathlib import Path
from datetime import datetime

# å¯¼å…¥æ¨¡å‹ç›¸å…³æ¨¡å— (å¸¦é”™è¯¯å¤„ç†)
try:
    from models import PETGNN
    MODEL_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
    MODEL_AVAILABLE = False

try:
    from preprocessing.data_loader import PETDataset
    DATA_LOADER_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ•°æ®åŠ è½½å™¨å¯¼å…¥å¤±è´¥: {e}")
    DATA_LOADER_AVAILABLE = False

try:
    import yaml
    CONFIG_AVAILABLE = True
except ImportError:
    print("âš ï¸ YAMLé…ç½®ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
    CONFIG_AVAILABLE = False

app = Flask(__name__)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('api_service.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
model = None
config = None
device = None

def load_model_and_config():
    """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
    global model, config, device
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        if not MODEL_AVAILABLE:
            logger.error("æ¨¡å‹ç±»ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ¨¡å‹å®ä¾‹")
            return False
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åŠ è½½é…ç½®
        if CONFIG_AVAILABLE:
            config_path = 'config/default.yaml'
            if Path(config_path).exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                logger.info("å·²åŠ è½½YAMLé…ç½®æ–‡ä»¶")
            else:
                logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                config = None
        else:
            logger.warning("YAMLä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            config = None
        
        # ä½¿ç”¨é»˜è®¤é…ç½®
        if config is None:
            config = {
                'model': {
                    'input_dim': 13,
                    'hidden_dim': 64,
                    'output_dim': 2,
                    'num_layers': 3,
                    'dropout': 0.1
                }
            }
        else:
            # ç¡®ä¿é…ç½®ä¸­æœ‰å¿…è¦çš„å­—æ®µ
            if 'model' not in config:
                config['model'] = {}
            
            # è®¾ç½®é»˜è®¤å€¼
            config['model'].setdefault('input_dim', 13)
            config['model'].setdefault('hidden_dim', config['model'].get('hidden_dim', 64))
            config['model'].setdefault('output_dim', config['model'].get('output_dim', 2))
            config['model'].setdefault('num_layers', 3)
            config['model'].setdefault('dropout', config['model'].get('dropout', 0.1))
        
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_paths = [
            'experiments/best_model.pth',
            'best_model.pth',
            'latest_checkpoint.pth',
            'experiments/latest_checkpoint.pth'
        ]
        
        model_path = None
        for path in model_paths:
            if Path(path).exists():
                model_path = path
                break
        
        if model_path:
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = PETGNN(
                input_dim=config['model']['input_dim'],
                hidden_dim=config['model']['hidden_dim'],
                output_dim=config['model']['output_dim'],
                num_layers=config['model']['num_layers'],
                dropout=config['model']['dropout']
            )
            
            # åŠ è½½æƒé‡
            try:
                checkpoint = torch.load(model_path, map_location=device)
                if 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    model.load_state_dict(checkpoint)
                
                model.to(device)
                model.eval()
                
                logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
                return True
                
            except Exception as e:
                logger.error(f"æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}")
                # åˆ›å»ºæœªè®­ç»ƒçš„æ¨¡å‹ä½œä¸ºfallback
                model = PETGNN(
                    input_dim=config['model']['input_dim'],
                    hidden_dim=config['model']['hidden_dim'],
                    output_dim=config['model']['output_dim'],
                    num_layers=config['model']['num_layers'],
                    dropout=config['model']['dropout']
                )
                model.to(device)
                model.eval()
                logger.warning("ä½¿ç”¨æœªè®­ç»ƒçš„æ¨¡å‹ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰")
                return True
        else:
            logger.warning("æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œåˆ›å»ºæ–°æ¨¡å‹")
            # åˆ›å»ºæ–°æ¨¡å‹
            model = PETGNN(
                input_dim=config['model']['input_dim'],
                hidden_dim=config['model']['hidden_dim'],
                output_dim=config['model']['output_dim'],
                num_layers=config['model']['num_layers'],
                dropout=config['model']['dropout']
            )
            model.to(device)
            model.eval()
            logger.warning("ä½¿ç”¨æœªè®­ç»ƒçš„æ¨¡å‹ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰")
            return True
            
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return False

def validate_input_data(data):
    """éªŒè¯è¾“å…¥æ•°æ®æ ¼å¼"""
    required_fields = [
        'x1', 'y1', 'z1', 'x2', 'y2', 'z2',
        'energy1', 'energy2', 'time1', 'time2'
    ]
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    for field in required_fields:
        if field not in data:
            return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    try:
        for field in required_fields:
            float(data[field])
    except (ValueError, TypeError):
        return False, f"å­—æ®µ {field} å¿…é¡»æ˜¯æ•°å€¼ç±»å‹"
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    if data['energy1'] <= 0 or data['energy2'] <= 0:
        return False, "èƒ½é‡å€¼å¿…é¡»å¤§äº0"
    
    return True, "æ•°æ®éªŒè¯é€šè¿‡"

def calculate_derived_features(data):
    """è®¡ç®—è¡ç”Ÿç‰¹å¾"""
    # è®¡ç®—è·ç¦»
    distance = np.sqrt(
        (data['x2'] - data['x1'])**2 + 
        (data['y2'] - data['y1'])**2 + 
        (data['z2'] - data['z1'])**2
    )
    
    # è®¡ç®—èƒ½é‡å·®
    energy_diff = abs(data['energy2'] - data['energy1'])
    
    # è®¡ç®—æ—¶é—´å·®
    time_diff = abs(data['time2'] - data['time1'])
    
    return {
        'distance': distance,
        'energy_diff': energy_diff,
        'time_diff': time_diff
    }

@app.route('/')
def home():
    """ä¸»é¡µ"""
    html_template = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>PETä½è€¦åˆäº‹ä»¶è¯†åˆ« API</title>
        <meta charset="UTF-8">
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }
            .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
            h1 { color: #2c3e50; text-align: center; }
            .api-info { background: #ecf0f1; padding: 20px; border-radius: 5px; margin: 20px 0; }
            .endpoint { background: #3498db; color: white; padding: 10px; border-radius: 5px; margin: 10px 0; }
            .status { padding: 10px; border-radius: 5px; margin: 10px 0; }
            .status.healthy { background: #2ecc71; color: white; }
            .status.unhealthy { background: #e74c3c; color: white; }
            code { background: #f8f9fa; padding: 2px 4px; border-radius: 3px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ”¬ PETä½è€¦åˆäº‹ä»¶è¯†åˆ« API</h1>
            
            <div class="status {{ 'healthy' if model_loaded else 'unhealthy' }}">
                <strong>æœåŠ¡çŠ¶æ€:</strong> {{ 'ğŸŸ¢ æ­£å¸¸è¿è¡Œ' if model_loaded else 'ğŸ”´ æ¨¡å‹æœªåŠ è½½' }}
            </div>
            
            <div class="api-info">
                <h3>ğŸ“‹ APIæ¥å£è¯´æ˜</h3>
                
                <div class="endpoint">
                    <strong>POST /predict</strong> - é¢„æµ‹PETäº‹ä»¶ç±»å‹
                </div>
                <p><strong>è¯·æ±‚ä½“ç¤ºä¾‹:</strong></p>
                <pre><code>{
  "x1": 100.0, "y1": 100.0, "z1": 100.0,
  "x2": 120.0, "y2": 120.0, "z2": 120.0,
  "energy1": 511.0, "energy2": 511.0,
  "time1": 1.0, "time2": 1.1
}</code></pre>
                
                <div class="endpoint">
                    <strong>GET /health</strong> - å¥åº·æ£€æŸ¥
                </div>
                
                <div class="endpoint">
                    <strong>GET /model_info</strong> - æ¨¡å‹ä¿¡æ¯
                </div>
                
                <div class="endpoint">
                    <strong>POST /batch_predict</strong> - æ‰¹é‡é¢„æµ‹
                </div>
            </div>
            
            <div class="api-info">
                <h3>ğŸ“Š è¿”å›æ ¼å¼</h3>
                <p>æˆåŠŸå“åº”ç¤ºä¾‹:</p>
                <pre><code>{
  "success": true,
  "prediction": {
    "label": 1,
    "label_name": "æœ‰æ•ˆäº‹ä»¶",
    "confidence": 0.95,
    "probability": [0.05, 0.95]
  },
  "features": {
    "distance": 34.6,
    "energy_diff": 0.0,
    "time_diff": 0.1
  },
  "timestamp": "2024-01-01T12:00:00"
}</code></pre>
            </div>
        </div>
    </body>
    </html>
    """
    return render_template_string(html_template, model_loaded=(model is not None))

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    status = {
        'status': 'healthy' if model is not None else 'unhealthy',
        'model_loaded': model is not None,
        'device': str(device) if device else 'unknown',
        'timestamp': datetime.now().isoformat()
    }
    
    return jsonify(status), 200 if model is not None else 503

@app.route('/model_info', methods=['GET'])
def model_info():
    """æ¨¡å‹ä¿¡æ¯æ¥å£"""
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 503
    
    info = {
        'model_type': 'PETGNN',
        'input_dim': config['model']['input_dim'],
        'hidden_dim': config['model']['hidden_dim'],
        'output_dim': config['model']['output_dim'],
        'num_layers': config['model']['num_layers'],
        'dropout': config['model']['dropout'],
        'device': str(device),
        'parameters': sum(p.numel() for p in model.parameters()),
        'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad)
    }
    
    return jsonify(info)

@app.route('/predict', methods=['POST'])
def predict():
    """å•ä¸ªæ ·æœ¬é¢„æµ‹æ¥å£"""
    try:
        if model is None:
            return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 503
        
        # è·å–è¾“å…¥æ•°æ®
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æä¾›JSONæ ¼å¼çš„è¾“å…¥æ•°æ®'}), 400
        
        # éªŒè¯è¾“å…¥æ•°æ®
        is_valid, message = validate_input_data(data)
        if not is_valid:
            return jsonify({'error': message}), 400
        
        # è®¡ç®—è¡ç”Ÿç‰¹å¾
        derived_features = calculate_derived_features(data)
        
        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        features = [
            data['x1'], data['y1'], data['z1'],
            data['x2'], data['y2'], data['z2'],
            data['energy1'], data['energy2'],
            data['time1'], data['time2'],
            derived_features['distance'],
            derived_features['energy_diff'],
            derived_features['time_diff']
        ]
        
        # è½¬æ¢ä¸ºtensor
        input_tensor = torch.FloatTensor(features).unsqueeze(0).to(device)
        
        # æ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = torch.max(probabilities).item()
        
        # å‡†å¤‡å“åº”
        class_names = ['ä½è€¦åˆäº‹ä»¶', 'æœ‰æ•ˆäº‹ä»¶']
        response = {
            'success': True,
            'prediction': {
                'label': predicted_class,
                'label_name': class_names[predicted_class],
                'confidence': round(confidence, 4),
                'probability': [round(p, 4) for p in probabilities[0].tolist()]
            },
            'features': {
                'distance': round(derived_features['distance'], 2),
                'energy_diff': round(derived_features['energy_diff'], 2),
                'time_diff': round(derived_features['time_diff'], 4)
            },
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"é¢„æµ‹å®Œæˆ: {class_names[predicted_class]} (ç½®ä¿¡åº¦: {confidence:.4f})")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        return jsonify({'error': f'é¢„æµ‹å¤±è´¥: {str(e)}'}), 500

@app.route('/batch_predict', methods=['POST'])
def batch_predict():
    """æ‰¹é‡é¢„æµ‹æ¥å£"""
    try:
        if model is None:
            return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 503
        
        # è·å–è¾“å…¥æ•°æ®
        data = request.get_json()
        if not data or 'samples' not in data:
            return jsonify({'error': 'è¯·æä¾›åŒ…å«sampleså­—æ®µçš„JSONæ•°æ®'}), 400
        
        samples = data['samples']
        if not isinstance(samples, list):
            return jsonify({'error': 'sampleså¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼'}), 400
        
        if len(samples) > 100:  # é™åˆ¶æ‰¹æ¬¡å¤§å°
            return jsonify({'error': 'æ‰¹æ¬¡å¤§å°ä¸èƒ½è¶…è¿‡100'}), 400
        
        results = []
        
        for i, sample in enumerate(samples):
            try:
                # éªŒè¯è¾“å…¥æ•°æ®
                is_valid, message = validate_input_data(sample)
                if not is_valid:
                    results.append({
                        'index': i,
                        'success': False,
                        'error': message
                    })
                    continue
                
                # è®¡ç®—è¡ç”Ÿç‰¹å¾
                derived_features = calculate_derived_features(sample)
                
                # å‡†å¤‡æ¨¡å‹è¾“å…¥
                features = [
                    sample['x1'], sample['y1'], sample['z1'],
                    sample['x2'], sample['y2'], sample['z2'],
                    sample['energy1'], sample['energy2'],
                    sample['time1'], sample['time2'],
                    derived_features['distance'],
                    derived_features['energy_diff'],
                    derived_features['time_diff']
                ]
                
                # è½¬æ¢ä¸ºtensor
                input_tensor = torch.FloatTensor(features).unsqueeze(0).to(device)
                
                # æ¨¡å‹é¢„æµ‹
                with torch.no_grad():
                    outputs = model(input_tensor)
                    probabilities = torch.softmax(outputs, dim=1)
                    predicted_class = torch.argmax(probabilities, dim=1).item()
                    confidence = torch.max(probabilities).item()
                
                # æ·»åŠ ç»“æœ
                class_names = ['ä½è€¦åˆäº‹ä»¶', 'æœ‰æ•ˆäº‹ä»¶']
                results.append({
                    'index': i,
                    'success': True,
                    'prediction': {
                        'label': predicted_class,
                        'label_name': class_names[predicted_class],
                        'confidence': round(confidence, 4),
                        'probability': [round(p, 4) for p in probabilities[0].tolist()]
                    },
                    'features': {
                        'distance': round(derived_features['distance'], 2),
                        'energy_diff': round(derived_features['energy_diff'], 2),
                        'time_diff': round(derived_features['time_diff'], 4)
                    }
                })
                
            except Exception as e:
                results.append({
                    'index': i,
                    'success': False,
                    'error': str(e)
                })
        
        # ç»Ÿè®¡ç»“æœ
        successful_predictions = sum(1 for r in results if r['success'])
        
        response = {
            'success': True,
            'total_samples': len(samples),
            'successful_predictions': successful_predictions,
            'failed_predictions': len(samples) - successful_predictions,
            'results': results,
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"æ‰¹é‡é¢„æµ‹å®Œæˆ: {successful_predictions}/{len(samples)} æˆåŠŸ")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"æ‰¹é‡é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        return jsonify({'error': f'æ‰¹é‡é¢„æµ‹å¤±è´¥: {str(e)}'}), 500

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'APIæ¥å£ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨PETä½è€¦åˆäº‹ä»¶è¯†åˆ«APIæœåŠ¡...")
    
    # åŠ è½½æ¨¡å‹
    if load_model_and_config():
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    else:
        print("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼ŒæœåŠ¡å°†ä»¥å—é™æ¨¡å¼è¿è¡Œ")
    
    # å¯åŠ¨æœåŠ¡
    print("ğŸŒ æœåŠ¡å¯åŠ¨åœ°å€: http://localhost:5000")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:5000")
    print("ğŸ’Š å¥åº·æ£€æŸ¥: http://localhost:5000/health")
    
    app.run(host='0.0.0.0', port=5000, debug=False) 