"""
PET-GNNæ¨¡å‹è®­ç»ƒè„šæœ¬
"""

import argparse
import yaml
import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
from pathlib import Path
import sys
from tqdm import tqdm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from models.gnn_model import PETGraphNet
from preprocessing.graph_dataset import PETGraphDataset, collate_graph_batch
from utils.logger import setup_logger


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='PET-GNNæ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--config', type=str, default='config/default.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', type=str, default=None,
                       help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--debug', action='store_true',
                       help='è°ƒè¯•æ¨¡å¼')
    
    return parser.parse_args()


def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def setup_device():
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        logging.info(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    else:
        device = torch.device('cpu')
        logging.info("ä½¿ç”¨CPU")
    return device


def create_model(config):
    """åˆ›å»ºæ¨¡å‹"""
    try:
        model = PETGraphNet(config)
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        logging.info(f"æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        logging.info(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
        logging.info(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        return model
    except Exception as e:
        logging.error(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        # å¦‚æœGNNæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„MLPä½œä¸ºå¤‡é€‰
        logging.info("ä½¿ç”¨ç®€å•MLPæ¨¡å‹ä½œä¸ºå¤‡é€‰...")
        return create_simple_model(config)


def create_simple_model(config):
    """åˆ›å»ºç®€å•çš„MLPæ¨¡å‹ä½œä¸ºå¤‡é€‰"""
    class SimpleMLP(nn.Module):
        def __init__(self, input_dim=10, hidden_dims=[64, 32], num_classes=2, dropout=0.1):
            super(SimpleMLP, self).__init__()
            layers = []
            prev_dim = input_dim
            
            for hidden_dim in hidden_dims:
                layers.extend([
                    nn.Linear(prev_dim, hidden_dim),
                    nn.ReLU(),
                    nn.BatchNorm1d(hidden_dim),
                    nn.Dropout(dropout)
                ])
                prev_dim = hidden_dim
            
            layers.append(nn.Linear(prev_dim, num_classes))
            self.network = nn.Sequential(*layers)
        
        def forward(self, x):
            return self.network(x)
    
    return SimpleMLP(input_dim=10, hidden_dims=[64, 32], num_classes=2)


def create_data_loaders(config):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    try:
        # å°è¯•ä½¿ç”¨å›¾æ•°æ®é›†
        train_dataset = PETGraphDataset(
            config, 
            data_file='data/processed/train_data.csv',
            split='train'
        )
        val_dataset = PETGraphDataset(
            config,
            data_file='data/processed/val_data.csv', 
            split='val'
        )
        
        train_loader = torch.utils.data.DataLoader(
            train_dataset,
            batch_size=config['training']['batch_size'],
            shuffle=True,
            collate_fn=collate_graph_batch,
            num_workers=0  # Windowså…¼å®¹æ€§
        )
        
        val_loader = torch.utils.data.DataLoader(
            val_dataset,
            batch_size=config['training']['batch_size'],
            shuffle=False,
            collate_fn=collate_graph_batch,
            num_workers=0
        )
        
        logging.info(f"å›¾æ•°æ®åŠ è½½æˆåŠŸ: è®­ç»ƒé›†{len(train_dataset)}, éªŒè¯é›†{len(val_dataset)}")
        return train_loader, val_loader, 'graph'
        
    except Exception as e:
        logging.warning(f"å›¾æ•°æ®åŠ è½½å¤±è´¥: {e}")
        logging.info("ä½¿ç”¨ç®€å•è¡¨æ ¼æ•°æ®...")
        return create_simple_data_loaders(config)


def create_simple_data_loaders(config):
    """åˆ›å»ºç®€å•çš„è¡¨æ ¼æ•°æ®åŠ è½½å™¨"""
    from simple_train import PETDataset
    
    try:
        train_dataset = PETDataset('data/processed/train_data.csv')
        val_dataset = PETDataset('data/processed/val_data.csv')
        
        train_loader = torch.utils.data.DataLoader(
            train_dataset,
            batch_size=config['training']['batch_size'],
            shuffle=True,
            num_workers=0
        )
        
        val_loader = torch.utils.data.DataLoader(
            val_dataset,
            batch_size=config['training']['batch_size'],
            shuffle=False,
            num_workers=0
        )
        
        logging.info(f"è¡¨æ ¼æ•°æ®åŠ è½½æˆåŠŸ: è®­ç»ƒé›†{len(train_dataset)}, éªŒè¯é›†{len(val_dataset)}")
        return train_loader, val_loader, 'tabular'
        
    except Exception as e:
        logging.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise


def create_optimizer(model, config):
    """åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨"""
    optimizer_name = config['training']['optimizer']
    lr = config['training']['learning_rate']
    weight_decay = config['training']['weight_decay']
    
    if optimizer_name == 'Adam':
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    elif optimizer_name == 'SGD':
        optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)
    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler_name = config['training'].get('scheduler', 'StepLR')
    if scheduler_name == 'StepLR':
        scheduler = torch.optim.lr_scheduler.StepLR(
            optimizer, 
            step_size=config['training'].get('step_size', 30),
            gamma=config['training'].get('gamma', 0.1)
        )
    else:
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
    
    return optimizer, scheduler


def create_loss_function(config):
    """åˆ›å»ºæŸå¤±å‡½æ•°"""
    loss_name = config['training'].get('loss_function', 'CrossEntropyLoss')
    
    if loss_name == 'CrossEntropyLoss':
        # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        class_weights = config['training'].get('class_weights', None)
        if class_weights:
            weight = torch.FloatTensor(class_weights)
            criterion = nn.CrossEntropyLoss(weight=weight)
        else:
            criterion = nn.CrossEntropyLoss()
    else:
        criterion = nn.CrossEntropyLoss()
    
    return criterion


def train_epoch(model, train_loader, optimizer, criterion, device, data_type='graph'):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    pbar = tqdm(train_loader, desc='è®­ç»ƒ')
    for batch_idx, batch in enumerate(pbar):
        
        if data_type == 'graph':
            # å›¾æ•°æ®
            x = batch['x'].to(device)
            edge_index = batch['edge_index'].to(device)
            edge_attr = batch.get('edge_attr', None)
            if edge_attr is not None:
                edge_attr = edge_attr.to(device)
            batch_tensor = batch['batch'].to(device)
            targets = batch['y'].to(device)
            
            optimizer.zero_grad()
            try:
                outputs = model(x, edge_index, batch_tensor, edge_attr)
            except:
                # å¦‚æœå›¾æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨äº‹ä»¶ç‰¹å¾
                event_features = batch['event_features'].to(device)
                outputs = model(event_features)
                
        else:
            # è¡¨æ ¼æ•°æ®
            data, targets = batch
            data, targets = data.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(data)
        
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        pred = outputs.argmax(dim=1)
        correct += pred.eq(targets).sum().item()
        total += targets.size(0)
        
        # æ›´æ–°è¿›åº¦æ¡
        accuracy = 100. * correct / total
        pbar.set_postfix({
            'Loss': f'{loss.item():.4f}',
            'Acc': f'{accuracy:.2f}%'
        })
    
    avg_loss = total_loss / len(train_loader)
    accuracy = 100. * correct / total
    
    return avg_loss, accuracy


def validate_epoch(model, val_loader, criterion, device, data_type='graph'):
    """éªŒè¯ä¸€ä¸ªepoch"""
    model.eval()
    total_loss = 0
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc='éªŒè¯'):
            
            if data_type == 'graph':
                # å›¾æ•°æ®
                x = batch['x'].to(device)
                edge_index = batch['edge_index'].to(device)
                edge_attr = batch.get('edge_attr', None)
                if edge_attr is not None:
                    edge_attr = edge_attr.to(device)
                batch_tensor = batch['batch'].to(device)
                targets = batch['y'].to(device)
                
                try:
                    outputs = model(x, edge_index, batch_tensor, edge_attr)
                except:
                    # å¦‚æœå›¾æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨äº‹ä»¶ç‰¹å¾
                    event_features = batch['event_features'].to(device)
                    outputs = model(event_features)
                    
            else:
                # è¡¨æ ¼æ•°æ®
                data, targets = batch
                data, targets = data.to(device), targets.to(device)
                outputs = model(data)
            
            loss = criterion(outputs, targets)
            total_loss += loss.item()
            
            pred = outputs.argmax(dim=1)
            all_preds.extend(pred.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())
    
    avg_loss = total_loss / len(val_loader)
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(all_targets, all_preds)
    precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_targets, all_preds, average='weighted', zero_division=0)
    
    return avg_loss, {
        'accuracy': accuracy,
        'precision': precision, 
        'recall': recall,
        'f1': f1
    }


def save_checkpoint(model, optimizer, epoch, metrics, config, is_best=False):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    save_dir = Path(config['experiment']['save_dir'])
    save_dir.mkdir(exist_ok=True)
    
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
        'config': config
    }
    
    # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
    checkpoint_path = save_dir / 'latest_checkpoint.pth'
    torch.save(checkpoint, checkpoint_path)
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if is_best:
        best_path = save_dir / 'best_model.pth'
        torch.save(checkpoint, best_path)
        logging.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {best_path}")


def main():
    # è§£æå‚æ•°
    args = parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(
        level=logging.DEBUG if args.debug else logging.INFO,
        log_file=f"{config['experiment']['save_dir']}/training.log"
    )
    
    logging.info("=" * 60)
    logging.info("ğŸš€ å¼€å§‹PET-GNNæ¨¡å‹è®­ç»ƒ")
    logging.info("=" * 60)
    
    # è®¾ç½®è®¾å¤‡
    device = setup_device()
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(config)
    model = model.to(device)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, data_type = create_data_loaders(config)
    
    # åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer, scheduler = create_optimizer(model, config)
    criterion = create_loss_function(config)
    criterion = criterion.to(device)
    
    # è®­ç»ƒè®¾ç½®
    epochs = config['training']['epochs']
    best_f1 = 0
    patience = config['training']['early_stopping']['patience']
    patience_counter = 0
    
    logging.info(f"è®­ç»ƒè®¾ç½®:")
    logging.info(f"  - æ•°æ®ç±»å‹: {data_type}")
    logging.info(f"  - è®­ç»ƒè½®æ•°: {epochs}")
    logging.info(f"  - æ‰¹å¤§å°: {config['training']['batch_size']}")
    logging.info(f"  - å­¦ä¹ ç‡: {config['training']['learning_rate']}")
    logging.info(f"  - æ—©åœè€å¿ƒ: {patience}")
    
    # æ¢å¤è®­ç»ƒ
    start_epoch = 0
    if args.resume:
        try:
            checkpoint = torch.load(args.resume, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            start_epoch = checkpoint['epoch'] + 1
            best_f1 = checkpoint['metrics']['f1']
            logging.info(f"ä»epoch {start_epoch}æ¢å¤è®­ç»ƒ")
        except Exception as e:
            logging.warning(f"æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {e}")
    
    # è®­ç»ƒå¾ªç¯
    logging.info("\nğŸ¯ å¼€å§‹è®­ç»ƒå¾ªç¯")
    for epoch in range(start_epoch, epochs):
        logging.info(f"\nEpoch {epoch+1}/{epochs}")
        logging.info("-" * 40)
        
        # è®­ç»ƒ
        train_loss, train_acc = train_epoch(
            model, train_loader, optimizer, criterion, device, data_type
        )
        
        # éªŒè¯
        val_loss, val_metrics = validate_epoch(
            model, val_loader, criterion, device, data_type
        )
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        # è®°å½•ç»“æœ
        logging.info(f"è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
        logging.info(f"éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_metrics['accuracy']*100:.2f}%")
        logging.info(f"      - Precision: {val_metrics['precision']:.4f}")
        logging.info(f"      - Recall: {val_metrics['recall']:.4f}")
        logging.info(f"      - F1: {val_metrics['f1']:.4f}")
        logging.info(f"å­¦ä¹ ç‡: {current_lr:.6f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        is_best = val_metrics['f1'] > best_f1
        if is_best:
            best_f1 = val_metrics['f1']
            patience_counter = 0
            logging.info(f"ğŸ‰ æ–°çš„æœ€ä½³F1åˆ†æ•°: {best_f1:.4f}")
        else:
            patience_counter += 1
        
        save_checkpoint(model, optimizer, epoch, val_metrics, config, is_best)
        
        # æ—©åœæ£€æŸ¥
        if patience_counter >= patience:
            logging.info(f"æ—©åœè§¦å‘ï¼Œå·²è¿ç»­{patience}è½®æ— æ”¹å–„")
            break
    
    logging.info("\n" + "=" * 60)
    logging.info("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    logging.info(f"æœ€ä½³F1åˆ†æ•°: {best_f1:.4f}")
    logging.info("=" * 60)


if __name__ == '__main__':
    main() 